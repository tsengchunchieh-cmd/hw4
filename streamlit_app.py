"""
Streamlit RAG Document QA System
A complete Retrieval-Augmented Generation (RAG) application for document-based question answering.

Features:
- Upload and process .pdf, .txt, and .docx files
- Create vector databases using Google's EmbeddingGemma-300m model
- Ask questions and receive answers based on document content
- View retrieved document chunks for transparency
"""

import streamlit as st
import os
import sys
from pathlib import Path

# Add current directory to path for local imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from embeddings import EmbeddingGemmaEmbeddings
from rag_chain import query_rag
from vector_store import create_vector_store, save_vectorstore, load_vectorstore


# ============================================================================
# Page Configuration
# ============================================================================

st.set_page_config(
    page_title="ğŸ“š RAG æ–‡ä»¶å•ç­”ç³»çµ±",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ“š RAG æ–‡ä»¶å•ç­”ç³»çµ±")
st.markdown("""
åŸºæ–¼å‘é‡è³‡æ–™åº«çš„æ–‡ä»¶å•ç­”ç³»çµ±ï¼Œä½¿ç”¨ Google çš„ EmbeddingGemma æ¨¡å‹å’Œ Gemini 2.5 Flashã€‚
""")


# ============================================================================
# Sidebar Configuration
# ============================================================================

with st.sidebar:
    st.header("âš™ï¸ é…ç½®")
    
    st.markdown("### API å¯†é‘°")
    hf_token = st.text_input(
        "HuggingFace Token (ç”¨æ–¼ EmbeddingGemma)",
        type="password",
        help="å¾ HuggingFace å–å¾—: https://huggingface.co/settings/tokens"
    )
    
    llm_api_key = st.text_input(
        "Google API Key (ç”¨æ–¼ Gemini 2.5 Flash)",
        type="password",
        help="å¾ Google AI Studio å–å¾—: https://aistudio.google.com/app/apikey"
    )
    
    st.markdown("### è³‡æ–™åº«é¸é …")
    db_mode = st.radio(
        "é¸æ“‡è³‡æ–™åº«æ¨¡å¼ï¼š",
        options=["å»ºç«‹æ–°è³‡æ–™åº«", "è¼‰å…¥ç¾æœ‰è³‡æ–™åº«"],
        help="å»ºç«‹æ–°è³‡æ–™åº«æˆ–å¾æœ¬åœ°è¼‰å…¥å·²ä¿å­˜çš„è³‡æ–™åº«"
    )


# ============================================================================
# Initialize Session State
# ============================================================================

if 'vectorstore' not in st.session_state:
    st.session_state['vectorstore'] = None

if 'db_created' not in st.session_state:
    st.session_state['db_created'] = False


# ============================================================================
# Main Application Layout
# ============================================================================

# Tab 1: Create Vector Store
tab1, tab2 = st.tabs(["ğŸ“¤ å»ºç«‹è³‡æ–™åº«", "â“ æå•"])

with tab1:
    st.header("ä¸Šå‚³æ–‡ä»¶ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«")
    
    if db_mode == "å»ºç«‹æ–°è³‡æ–™åº«":
        st.markdown("""
        ### æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        - **PDF** (.pdf)
        - **Word æ–‡ä»¶** (.docx)
        - **ç´”æ–‡å­—** (.txt)
        """)
        
        uploaded_files = st.file_uploader(
            "ä¸Šå‚³æ‚¨çš„æ–‡ä»¶",
            type=["pdf", "txt", "docx"],
            accept_multiple_files=True,
            help="å¯åŒæ™‚ä¸Šå‚³å¤šå€‹æ–‡ä»¶"
        )
        
        if uploaded_files:
            st.markdown(f"**å·²é¸æ“‡ {len(uploaded_files)} å€‹æ–‡ä»¶ï¼š**")
            for file in uploaded_files:
                st.write(f"- {file.name} ({file.size} bytes)")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            if st.button("ğŸ”¨ å»ºç«‹å‘é‡è³‡æ–™åº«", use_container_width=True, type="primary"):
                if not uploaded_files:
                    st.error("è«‹å…ˆé¸æ“‡è‡³å°‘ä¸€å€‹æ–‡ä»¶ã€‚")
                elif not hf_token:
                    st.error("è«‹è¼¸å…¥ HuggingFace Tokenã€‚")
                else:
                    with st.spinner("æ­£åœ¨è™•ç†æ–‡ä»¶ä¸¦å»ºç«‹è³‡æ–™åº«..."):
                        try:
                            st.session_state['vectorstore'] = create_vector_store(
                                uploaded_files,
                                hf_token
                            )
                            st.session_state['db_created'] = True
                            st.success("âœ… å‘é‡è³‡æ–™åº«å»ºç«‹æˆåŠŸï¼")
                            st.balloons()
                        except Exception as e:
                            st.error(f"âŒ å»ºç«‹è³‡æ–™åº«æ™‚å‡ºéŒ¯ï¼š{str(e)}")
        
        with col2:
            if st.button("ğŸ’¾ ä¿å­˜è³‡æ–™åº«", use_container_width=True):
                if st.session_state['vectorstore'] is not None:
                    try:
                        save_vectorstore(st.session_state['vectorstore'], "faiss_db")
                        st.success("âœ… è³‡æ–™åº«å·²ä¿å­˜ï¼")
                    except Exception as e:
                        st.error(f"âŒ ä¿å­˜è³‡æ–™åº«æ™‚å‡ºéŒ¯ï¼š{str(e)}")
                else:
                    st.warning("âš ï¸ è«‹å…ˆå»ºç«‹å‘é‡è³‡æ–™åº«ã€‚")
    
    else:  # Load existing database
        st.markdown("### è¼‰å…¥å·²ä¿å­˜çš„å‘é‡è³‡æ–™åº«")
        
        if os.path.exists("faiss_db"):
            if st.button("ğŸ“‚ è¼‰å…¥ faiss_db è³‡æ–™åº«", use_container_width=True, type="primary"):
                with st.spinner("æ­£åœ¨è¼‰å…¥è³‡æ–™åº«..."):
                    try:
                        st.session_state['vectorstore'] = load_vectorstore("faiss_db")
                        st.session_state['db_created'] = True
                        st.success("âœ… è³‡æ–™åº«è¼‰å…¥æˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"âŒ è¼‰å…¥è³‡æ–™åº«æ™‚å‡ºéŒ¯ï¼š{str(e)}")
        else:
            st.info("â„¹ï¸ æœªæ‰¾åˆ°å·²ä¿å­˜çš„è³‡æ–™åº«ã€‚è«‹å…ˆå»ºç«‹æ–°è³‡æ–™åº«ã€‚")
    
    # Display database status
    st.markdown("---")
    st.markdown("### è³‡æ–™åº«ç‹€æ…‹")
    if st.session_state['db_created'] and st.session_state['vectorstore'] is not None:
        st.success("âœ… è³‡æ–™åº«å·²æº–å‚™å¥½é€²è¡ŒæŸ¥è©¢")
    else:
        st.info("â„¹ï¸ è³‡æ–™åº«æœªæº–å‚™å¥½ï¼Œè«‹å…ˆå»ºç«‹æˆ–è¼‰å…¥ã€‚")


# Tab 2: Question Answering
with tab2:
    st.header("æå•èˆ‡å›ç­”")
    
    if st.session_state['vectorstore'] is not None:
        query = st.text_area(
            "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼š",
            height=100,
            placeholder="ä¾‹å¦‚ï¼šé€™ä»½æ–‡ä»¶ä¸»è¦è¨è«–äº†ä»€éº¼ï¼Ÿ",
            help="è¼¸å…¥ä»»ä½•èˆ‡ä¸Šå‚³æ–‡ä»¶ç›¸é—œçš„å•é¡Œ"
        )
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            submit_button = st.button(
                "ğŸš€ å–å¾—ç­”æ¡ˆ",
                use_container_width=True,
                type="primary"
            )
        
        with col2:
            clear_button = st.button(
                "ğŸ—‘ï¸ æ¸…ç©º",
                use_container_width=True
            )
        
        if clear_button:
            st.rerun()
        
        if submit_button and query.strip():
            if not llm_api_key:
                st.error("âŒ è«‹åœ¨å´é‚Šæ¬„è¼¸å…¥ Google API Keyã€‚")
            else:
                with st.spinner("æ­£åœ¨æª¢ç´¢ä¸¦ç”Ÿæˆç­”æ¡ˆ..."):
                    try:
                        vectorstore = st.session_state['vectorstore']
                        
                        # Execute RAG query
                        final_answer, retrieved_docs = query_rag(
                            vectorstore,
                            query,
                            llm_api_key
                        )
                        
                        # Display final answer
                        st.markdown("---")
                        st.subheader("ğŸ¤– æœ€çµ‚ç­”æ¡ˆ")
                        st.success(final_answer)
                        
                        # Display retrieved context
                        st.subheader("ğŸ“š æª¢ç´¢åˆ°çš„æ–‡ä»¶ç‰‡æ®µ (Context)")
                        
                        if retrieved_docs:
                            st.markdown(f"**æ‰¾åˆ° {len(retrieved_docs)} å€‹ç›¸é—œç‰‡æ®µï¼š**")
                            
                            for i, doc in enumerate(retrieved_docs, 1):
                                source_info = doc.metadata.get('source', 'æœªçŸ¥æ–‡ä»¶')
                                
                                with st.expander(
                                    f"ğŸ“„ ç‰‡æ®µ {i} (ä¾†è‡ª: {source_info})",
                                    expanded=(i == 1)
                                ):
                                    st.markdown(doc.page_content)
                        else:
                            st.info("â„¹ï¸ æœªæª¢ç´¢åˆ°ç›¸é—œæ–‡ä»¶ç‰‡æ®µã€‚")
                    
                    except Exception as e:
                        st.error(f"âŒ åŸ·è¡ŒæŸ¥è©¢æ™‚å‡ºéŒ¯ï¼š{str(e)}")
        
        elif submit_button:
            st.warning("âš ï¸ è«‹è¼¸å…¥å•é¡Œã€‚")
    
    else:
        st.info(
            "â„¹ï¸ è«‹å…ˆåœ¨ã€Œå»ºç«‹è³‡æ–™åº«ã€æ¨™ç±¤ä¸­å»ºç«‹æˆ–è¼‰å…¥å‘é‡è³‡æ–™åº«ã€‚"
        )


# ============================================================================
# Footer
# ============================================================================

st.markdown("---")
st.markdown("""
<div style='text-align: center'>
    <small>
        ğŸš€ ç”± Streamlitã€LangChainã€å’Œ Google Gemini é©…å‹• | 
        ğŸ“š ä½¿ç”¨ EmbeddingGemma-300m é€²è¡Œå‘é‡åŒ–
    </small>
</div>
""", unsafe_allow_html=True)
